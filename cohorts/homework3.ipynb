{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3d172ab",
   "metadata": {},
   "source": [
    "## Homework: Search Evaluation\n",
    "\n",
    "In this homework, we will evaluate the results of vector\n",
    "search.\n",
    "\n",
    "> It's possible that your answers won't match exactly. If it's the case, select the closest one.\n",
    "\n",
    "\n",
    "## Required libraries\n",
    "\n",
    "We will use minsearch and Qdrant. Make sure you have the most up-to-date versions:\n",
    "\n",
    "```bash\n",
    "pip install -U minsearch qdrant_client\n",
    "``` \n",
    "\n",
    "minsearch should be at least 0.0.4.\n",
    "\n",
    "\n",
    "\n",
    "## Evaluation data\n",
    "\n",
    "For this homework, we will use the same dataset we generated\n",
    "in the videos.\n",
    "\n",
    "Let's get them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a34c850",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "url_prefix = 'https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/main/03-evaluation/'\n",
    "docs_url = url_prefix + 'search_evaluation/documents-with-ids.json'\n",
    "documents = requests.get(docs_url).json()\n",
    "\n",
    "ground_truth_url = url_prefix + 'search_evaluation/ground-truth-data.csv'\n",
    "df_ground_truth = pd.read_csv(ground_truth_url)\n",
    "ground_truth = df_ground_truth.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51453e28",
   "metadata": {},
   "source": [
    "Here, `documents` contains the documents from the FAQ database\n",
    "with unique IDs, and `ground_truth` contains generated\n",
    "question-answer pairs. \n",
    "\n",
    "Also, we will need the code for evaluating retrieval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e2f884b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    return cnt / len(relevance_total)\n",
    "\n",
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "\n",
    "    return total_score / len(relevance_total)\n",
    "\n",
    "def evaluate(ground_truth, search_function):\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['document']\n",
    "        results = search_function(q)\n",
    "        relevance = [d['id'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172e4792",
   "metadata": {},
   "source": [
    "## Q1. Minsearch text\n",
    "\n",
    "Now let's evaluate our usual minsearch approach, but tweak\n",
    "the parameters. Let's use the following boosting \n",
    "params:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4e3f835",
   "metadata": {},
   "outputs": [],
   "source": [
    "boost = {'question': 1.5, 'section': 0.1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5102ff52",
   "metadata": {},
   "source": [
    "What's the hitrate for this approach?\n",
    "\n",
    "* 0.64\n",
    "* 0.74\n",
    "* 0.84\n",
    "* 0.94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ca23581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.minsearch.Index at 0x72ec4871fa10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import minsearch\n",
    "\n",
    "index = minsearch.Index(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\", \"id\"]\n",
    ")\n",
    "\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daa92840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minsearch_search(query, course):\n",
    "    boost = {'question': 1.5, 'section': 0.1}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': course},\n",
    "        boost_dict=boost,\n",
    "        num_results=5\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21b6095c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9782db2025eb4ac4b8533baa19821a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4627 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "relevance_total = []\n",
    "\n",
    "for q in tqdm(ground_truth):\n",
    "    doc_id = q['document']\n",
    "    results = minsearch_search(query=q['question'], course=q['course'])\n",
    "    relevance = [d['id'] == doc_id for d in results]\n",
    "    relevance_total.append(relevance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0b3920e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.848714069591528"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hit_rate(relevance_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477e9fd6",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "## Q1 ANSWER\n",
    "c) 0.84"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a490dd",
   "metadata": {},
   "source": [
    "## Embeddings \n",
    "\n",
    "The latest version of minsearch also supports vector search. \n",
    "We will use it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f199cadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from minsearch import VectorSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88eccabb",
   "metadata": {},
   "source": [
    "We will also use TF-IDF and Singular Value Decomposition to \n",
    "create embeddings from texts. You can refer to our\n",
    "[\"Create Your Own Search Engine\" workshop](https://github.com/alexeygrigorev/build-your-own-search-engine)\n",
    "if you want to know more about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72fcc502",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ab957e",
   "metadata": {},
   "source": [
    "Let's create embeddings for the \"question\" field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9956bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "\n",
    "for doc in documents:\n",
    "    t = doc['question']\n",
    "    texts.append(t)\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(min_df=3),\n",
    "    TruncatedSVD(n_components=128, random_state=1)\n",
    ")\n",
    "X = pipeline.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc11bf83",
   "metadata": {},
   "source": [
    "## Q2. Vector search for question\n",
    "\n",
    "Now let's index these embeddings with minsearch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e132fc6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.vector.VectorSearch at 0x72ec165e11f0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vindex = VectorSearch(keyword_fields={'course'})\n",
    "vindex.fit(X, documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba7fb78",
   "metadata": {},
   "source": [
    "Evaluate this seach method. What's MRR for it?\n",
    "\n",
    "- 0.25\n",
    "- 0.35\n",
    "- 0.45\n",
    "- 0.55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc01c075",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_search(query, course):\n",
    "\n",
    "\n",
    "    results = vindex.search(\n",
    "        query_vector=query,\n",
    "        filter_dict={'course': course},\n",
    "        num_results=5\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b696ab49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7540d415ddc647b19b5701daa3877919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4627 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "q2_relevance_total = []\n",
    "\n",
    "for q in tqdm(ground_truth):\n",
    "    doc_id = q['document']\n",
    "    query_vector = pipeline.transform([q['question']])\n",
    "    results = vector_search(query=query_vector, course=q['course'])\n",
    "    relevance = [d['id'] == doc_id for d in results]\n",
    "    q2_relevance_total.append(relevance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe712e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3571284489590088"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrr(q2_relevance_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dc78c7",
   "metadata": {},
   "source": [
    "## Q2 ANSWER\n",
    "b) 0.35"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503076dd",
   "metadata": {},
   "source": [
    "## Q3. Vector search for question and answer\n",
    "\n",
    "We only used question in Q2. We can use both question and answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58f74677",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "\n",
    "for doc in documents:\n",
    "    t = doc['question'] + ' ' + doc['text']\n",
    "    texts.append(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b3221e",
   "metadata": {},
   "source": [
    "Using the same pipeline (`min_df=3 for TF-IDF vectorizer and `n_components=128` for SVD), evaluate the performance of this\n",
    "approach\n",
    "\n",
    "What's the hitrate?\n",
    "\n",
    "- 0.62\n",
    "- 0.72\n",
    "- 0.82\n",
    "- 0.92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96af6296",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(min_df=3),\n",
    "    TruncatedSVD(n_components=128, random_state=1)\n",
    ")\n",
    "X = pipeline.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d624ecbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.vector.VectorSearch at 0x72ec177b82c0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vindex = VectorSearch(keyword_fields={'course'})\n",
    "vindex.fit(X, documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3715eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "876b84979d874795ac566762241d31a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4627 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "q3_relevance_total = []\n",
    "\n",
    "for q in tqdm(ground_truth):\n",
    "    doc_id = q['document']\n",
    "    query_vector = pipeline.transform([q['question']])\n",
    "    results = vector_search(query=query_vector, course=q['course'])\n",
    "    relevance = [d['id'] == doc_id for d in results]\n",
    "    q3_relevance_total.append(relevance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2bc92a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8210503566025502"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hit_rate(q3_relevance_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1b1efa",
   "metadata": {},
   "source": [
    "## Q3 ANSWER\n",
    "c) 0.82"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12074c02",
   "metadata": {},
   "source": [
    "## Q4. Qdrant\n",
    "\n",
    "Now let's evaluate the following settings in Qdrant:\n",
    "\n",
    "- `text = doc['question'] + ' ' + doc['text']`\n",
    "- `model_handle = \"jinaai/jina-embeddings-v2-small-en\"`\n",
    "- `limit = 5`\n",
    "\n",
    "What's the MRR?\n",
    "\n",
    "- 0.65\n",
    "- 0.75\n",
    "- 0.85\n",
    "- 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad5184a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "client = QdrantClient(\"http://localhost:6333\") #connecting to local Qdrant instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5f47f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install fastembed --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dcbdc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastembed import TextEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e86c61fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"model\": \"BAAI/bge-small-zh-v1.5\",\n",
      "   \"sources\": {\n",
      "      \"hf\": \"Qdrant/bge-small-zh-v1.5\",\n",
      "      \"url\": \"https://storage.googleapis.com/qdrant-fastembed/fast-bge-small-zh-v1.5.tar.gz\",\n",
      "      \"_deprecated_tar_struct\": true\n",
      "   },\n",
      "   \"model_file\": \"model_optimized.onnx\",\n",
      "   \"description\": \"Text embeddings, Unimodal (text), Chinese, 512 input tokens truncation, Prefixes for queries/documents: not so necessary, 2023 year.\",\n",
      "   \"license\": \"mit\",\n",
      "   \"size_in_GB\": 0.09,\n",
      "   \"additional_files\": [],\n",
      "   \"dim\": 512,\n",
      "   \"tasks\": {}\n",
      "}\n",
      "{\n",
      "   \"model\": \"Qdrant/clip-ViT-B-32-text\",\n",
      "   \"sources\": {\n",
      "      \"hf\": \"Qdrant/clip-ViT-B-32-text\",\n",
      "      \"url\": null,\n",
      "      \"_deprecated_tar_struct\": false\n",
      "   },\n",
      "   \"model_file\": \"model.onnx\",\n",
      "   \"description\": \"Text embeddings, Multimodal (text&image), English, 77 input tokens truncation, Prefixes for queries/documents: not necessary, 2021 year\",\n",
      "   \"license\": \"mit\",\n",
      "   \"size_in_GB\": 0.25,\n",
      "   \"additional_files\": [],\n",
      "   \"dim\": 512,\n",
      "   \"tasks\": {}\n",
      "}\n",
      "{\n",
      "   \"model\": \"jinaai/jina-embeddings-v2-small-en\",\n",
      "   \"sources\": {\n",
      "      \"hf\": \"xenova/jina-embeddings-v2-small-en\",\n",
      "      \"url\": null,\n",
      "      \"_deprecated_tar_struct\": false\n",
      "   },\n",
      "   \"model_file\": \"onnx/model.onnx\",\n",
      "   \"description\": \"Text embeddings, Unimodal (text), English, 8192 input tokens truncation, Prefixes for queries/documents: not necessary, 2023 year.\",\n",
      "   \"license\": \"apache-2.0\",\n",
      "   \"size_in_GB\": 0.12,\n",
      "   \"additional_files\": [],\n",
      "   \"dim\": 512,\n",
      "   \"tasks\": {}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "EMBEDDING_DIMENSIONALITY = 512\n",
    "\n",
    "for model in TextEmbedding.list_supported_models():\n",
    "    if model[\"dim\"] == EMBEDDING_DIMENSIONALITY:\n",
    "        print(json.dumps(model, indent=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbb72a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIMENSIONALITY = 512\n",
    "#model_handle = TextEmbedding(model_name=\"jinaai/jina-embeddings-v2-small-en\")\n",
    "model_handle = \"jinaai/jina-embeddings-v2-small-en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8056f973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the collection name\n",
    "collection_name = \"homework3\"\n",
    "if client.collection_exists(collection_name):\n",
    "    client.delete_collection(collection_name)                               \n",
    "# Create the collection with specified vector parameters\n",
    "client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=EMBEDDING_DIMENSIONALITY,  # Dimensionality of the vectors\n",
    "        distance=models.Distance.COSINE  # Distance metric for similarity search\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f1d4cd8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'documents' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m points = []\n\u001b[32m      2\u001b[39m \u001b[38;5;28mid\u001b[39m = \u001b[32m0\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdocuments\u001b[49m:\n\u001b[32m      6\u001b[39m     text = doc[\u001b[33m'\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m'\u001b[39m] + \u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m + doc[\u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      7\u001b[39m     point = models.PointStruct(\n\u001b[32m      8\u001b[39m         \u001b[38;5;28mid\u001b[39m=\u001b[38;5;28mid\u001b[39m,\n\u001b[32m      9\u001b[39m         vector=models.Document(text=text, model=model_handle), \u001b[38;5;66;03m#embed text locally with \"jinaai/jina-embeddings-v2-small-en\" from FastEmbed\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m         } \u001b[38;5;66;03m#save all needed metadata fields\u001b[39;00m\n\u001b[32m     16\u001b[39m     )\n",
      "\u001b[31mNameError\u001b[39m: name 'documents' is not defined"
     ]
    }
   ],
   "source": [
    "points = []\n",
    "id = 0\n",
    "\n",
    "\n",
    "for doc in documents:\n",
    "    text = doc['question'] + ' ' + doc['text']\n",
    "    point = models.PointStruct(\n",
    "        id=id,\n",
    "        vector=models.Document(text=text, model=model_handle), #embed text locally with \"jinaai/jina-embeddings-v2-small-en\" from FastEmbed\n",
    "        payload={\n",
    "            \"text\": doc['text'],\n",
    "            \"section\": doc['section'],\n",
    "            \"course\": doc['course'],\n",
    "            \"doc_id\": doc['id'],\n",
    "        } #save all needed metadata fields\n",
    "    )\n",
    "    points.append(point)\n",
    "\n",
    "    id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4406adae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.upsert(\n",
    "    collection_name=collection_name,\n",
    "    points=points\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2c87b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, limit=5):\n",
    "\n",
    "    results = client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=models.Document( \n",
    "            text=query,\n",
    "            model=model_handle\n",
    "        ),\n",
    "        limit=limit, # top closest matches\n",
    "        with_payload=True #to get metadata in the results\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e65ba7fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf701686f33f4829892496bd5292b911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4627 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "q4_relevance_total = []\n",
    "\n",
    "for q in tqdm(ground_truth):\n",
    "    doc_id = q['document']\n",
    "    results = search(query=q['question'])\n",
    "    relevance = [d.payload[\"doc_id\"] == doc_id for d in results.points]\n",
    "    q4_relevance_total.append(relevance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3130872a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54999669",
   "metadata": {},
   "outputs": [],
   "source": [
    "mrr(q4_relevance_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8246091780131126"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrr(q4_relevance_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a1068c",
   "metadata": {},
   "source": [
    "## Q4 ANSWER\n",
    "c) 0.85"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3d51e1",
   "metadata": {},
   "source": [
    "## Q5. Cosine simiarity\n",
    "\n",
    "In the second part of the module, we looked at evaluating\n",
    "the entire RAG approach. In particular, we looked at \n",
    "comparing the answer generated by our system with the actual\n",
    "answer from the FAQ.\n",
    "\n",
    "One of the ways of doing it is using the cosine similarity. \n",
    "Let's see how to calculate it.\n",
    "\n",
    "Cosine similarity is a dot product between two normalized vectors.\n",
    "In geometrical sense, it's the cosine of the angle between\n",
    "the vectors. Look up \"cosine similarity geometry\" if you want to\n",
    "learn more about it.\n",
    "\n",
    "For us, it means that we need two things:\n",
    "\n",
    "- First, we normalize each of the vectors\n",
    "- Then, compute the dot product\n",
    "\n",
    "So, we get this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16384663",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(u, v):\n",
    "    u = normalize(u)\n",
    "    v = normalize(v)\n",
    "    return u.dot(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f1db63",
   "metadata": {},
   "source": [
    "For normalization, we first compute the vector norm (its length),\n",
    "and then divide the vector by it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ecc718e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def normalize(u):\n",
    "    norm = np.sqrt(u.dot(u))\n",
    "    return u / norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f9b23a",
   "metadata": {},
   "source": [
    "Or we can simplify it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c405b156",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(u, v):\n",
    "    u_norm = np.sqrt(u.dot(u))\n",
    "    v_norm = np.sqrt(v.dot(v))\n",
    "    return u.dot(v) / (u_norm * v_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d803ea",
   "metadata": {},
   "source": [
    "Now let's use this function to compute the\n",
    "A->Q->A cosine similarity.\n",
    "\n",
    "We will use the results from [our gpt-4o-mini evaluations](https://github.com/DataTalksClub/llm-zoomcamp/blob/main/03-evaluation/rag_evaluation/data/results-gpt4o-mini.csv):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8423974d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_url = url_prefix + 'rag_evaluation/data/results-gpt4o-mini.csv'\n",
    "df_results = pd.read_csv(results_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a1d3e8",
   "metadata": {},
   "source": [
    "When creating embeddings, we will use a simple way -\n",
    "the same we used in the [Embeddings](#embeddings) section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6d9c49c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(min_df=3),\n",
    "    TruncatedSVD(n_components=128, random_state=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39245252",
   "metadata": {},
   "source": [
    "Let's fit the vectorizer on all the text data we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "91b2065c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidfvectorizer&#x27;, TfidfVectorizer(min_df=3)),\n",
       "                (&#x27;truncatedsvd&#x27;,\n",
       "                 TruncatedSVD(n_components=128, random_state=1))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;tfidfvectorizer&#x27;, TfidfVectorizer(min_df=3)),\n",
       "                (&#x27;truncatedsvd&#x27;,\n",
       "                 TruncatedSVD(n_components=128, random_state=1))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>TfidfVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer(min_df=3)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>TruncatedSVD</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.decomposition.TruncatedSVD.html\">?<span>Documentation for TruncatedSVD</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>TruncatedSVD(n_components=128, random_state=1)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer(min_df=3)),\n",
       "                ('truncatedsvd',\n",
       "                 TruncatedSVD(n_components=128, random_state=1))])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(df_results.answer_llm + ' ' + df_results.answer_orig + ' ' + df_results.question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca497551",
   "metadata": {},
   "source": [
    "Now use the `transform` methon of the pipeline to create the embeddings and calculate the cosine similarity between each\n",
    "pair.\n",
    "\n",
    "What's the average cosine?\n",
    "\n",
    "- 0.64\n",
    "- 0.74\n",
    "- 0.84\n",
    "- 0.94\n",
    "\n",
    "This is how you do it:\n",
    "\n",
    "- For each answer pair, compute\n",
    "    - `v_llm` for the answer from the LLM \n",
    "    - `v_orig` for the original answer\n",
    "    - then compute the cosine between them\n",
    "- At the end, take the average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c454ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_llm = pipeline.transform(df_results.answer_llm)\n",
    "v_orig = pipeline.transform(df_results.answer_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f101d3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_vector = []\n",
    "for i, j in zip(v_llm, v_orig):\n",
    "    row_cosine = cosine(i, j)\n",
    "    cosine_vector.append(row_cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c91ff034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8415841233490402)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cosine_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8445e6c",
   "metadata": {},
   "source": [
    "## Q5 ANSWER \n",
    "c) 0.84"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bac5cb",
   "metadata": {},
   "source": [
    "## Q6. Rouge\n",
    "\n",
    "And alternative way to see how two texts are similar is ROUGE. \n",
    "\n",
    "This is a set of metrics that compares two answers based on the overlap of n-grams, word sequences, and word pairs.\n",
    "\n",
    "It can give a more nuanced view of text similarity than just cosine similarity alone.\n",
    "\n",
    "We don't need to implement it ourselves, there's a python package for it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ba9774a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge\n",
      "  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: six in /home/codespace/.local/lib/python3.12/site-packages (from rouge) (1.17.0)\n",
      "Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: rouge\n",
      "Successfully installed rouge-1.0.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43ac381",
   "metadata": {},
   "source": [
    "(The latest version at the moment of writing is `1.0.1`)\n",
    "\n",
    "Let's compute the ROUGE score between the answers at the index 10 of our dataframe (`doc_id=5170565b`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e5e53d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "answer_llm     Yes, all sessions are recorded, so if you miss...\n",
       "answer_orig    Everything is recorded, so you won’t miss anyt...\n",
       "document                                                5170565b\n",
       "question                    Are sessions recorded if I miss one?\n",
       "course                                 machine-learning-zoomcamp\n",
       "Name: 10, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2bb74efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'r': 0.45454545454545453,\n",
       "  'p': 0.45454545454545453,\n",
       "  'f': 0.45454544954545456},\n",
       " 'rouge-2': {'r': 0.21621621621621623,\n",
       "  'p': 0.21621621621621623,\n",
       "  'f': 0.21621621121621637},\n",
       " 'rouge-l': {'r': 0.3939393939393939,\n",
       "  'p': 0.3939393939393939,\n",
       "  'f': 0.393939388939394}}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "rouge_scorer = Rouge()\n",
    "\n",
    "r = df_results.iloc[10]\n",
    "scores = rouge_scorer.get_scores(r.answer_llm, r.answer_orig)[0]\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8337aede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45454544954545456"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores['rouge-1']['f']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94171e24",
   "metadata": {},
   "source": [
    "There are three scores: `rouge-1`, `rouge-2` and `rouge-l`, and precision, recall and F1 score for each.\n",
    "\n",
    "* `rouge-1` - the overlap of unigrams,\n",
    "* `rouge-2` - bigrams,\n",
    "* `rouge-l` - the longest common subsequence\n",
    "\n",
    "For the 10th document, Rouge-1 F1 score is 0.45\n",
    "\n",
    "Let's compute it for the pairs in the entire dataframe.\n",
    "What's the average Rouge-1 F1?\n",
    "\n",
    "- 0.25\n",
    "- 0.35\n",
    "- 0.45\n",
    "- 0.55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "de2e00a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_llm</th>\n",
       "      <th>answer_orig</th>\n",
       "      <th>document</th>\n",
       "      <th>question</th>\n",
       "      <th>course</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You can sign up for the course by visiting the...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Where can I sign up for the course?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You can sign up using the link provided in the...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Can you provide a link to sign up?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes, there is an FAQ for the Machine Learning ...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Is there an FAQ for this Machine Learning course?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The context does not provide any specific info...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Does this course have a GitHub repository for ...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>To structure your questions and answers for th...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>How can I structure my questions and answers f...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>Some suggested titles for listing the Machine ...</td>\n",
       "      <td>I’ve seen LinkedIn users list DataTalksClub as...</td>\n",
       "      <td>c6a22665</td>\n",
       "      <td>What are some suggested titles for listing the...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1826</th>\n",
       "      <td>It is best advised that you do not list the Ma...</td>\n",
       "      <td>I’ve seen LinkedIn users list DataTalksClub as...</td>\n",
       "      <td>c6a22665</td>\n",
       "      <td>Should I list the Machine Learning Zoomcamp ex...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1827</th>\n",
       "      <td>You can incorporate your Machine Learning Zoom...</td>\n",
       "      <td>I’ve seen LinkedIn users list DataTalksClub as...</td>\n",
       "      <td>c6a22665</td>\n",
       "      <td>In which LinkedIn sections can I incorporate m...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1828</th>\n",
       "      <td>The advice on including a project link in a CV...</td>\n",
       "      <td>I’ve seen LinkedIn users list DataTalksClub as...</td>\n",
       "      <td>c6a22665</td>\n",
       "      <td>Who gave advice on including a project link in...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1829</th>\n",
       "      <td>The suggestion to showcase progress through Li...</td>\n",
       "      <td>I’ve seen LinkedIn users list DataTalksClub as...</td>\n",
       "      <td>c6a22665</td>\n",
       "      <td>Who suggested showcasing progress through Link...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1830 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             answer_llm  \\\n",
       "0     You can sign up for the course by visiting the...   \n",
       "1     You can sign up using the link provided in the...   \n",
       "2     Yes, there is an FAQ for the Machine Learning ...   \n",
       "3     The context does not provide any specific info...   \n",
       "4     To structure your questions and answers for th...   \n",
       "...                                                 ...   \n",
       "1825  Some suggested titles for listing the Machine ...   \n",
       "1826  It is best advised that you do not list the Ma...   \n",
       "1827  You can incorporate your Machine Learning Zoom...   \n",
       "1828  The advice on including a project link in a CV...   \n",
       "1829  The suggestion to showcase progress through Li...   \n",
       "\n",
       "                                            answer_orig  document  \\\n",
       "0     Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "1     Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "2     Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "3     Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "4     Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "...                                                 ...       ...   \n",
       "1825  I’ve seen LinkedIn users list DataTalksClub as...  c6a22665   \n",
       "1826  I’ve seen LinkedIn users list DataTalksClub as...  c6a22665   \n",
       "1827  I’ve seen LinkedIn users list DataTalksClub as...  c6a22665   \n",
       "1828  I’ve seen LinkedIn users list DataTalksClub as...  c6a22665   \n",
       "1829  I’ve seen LinkedIn users list DataTalksClub as...  c6a22665   \n",
       "\n",
       "                                               question  \\\n",
       "0                   Where can I sign up for the course?   \n",
       "1                    Can you provide a link to sign up?   \n",
       "2     Is there an FAQ for this Machine Learning course?   \n",
       "3     Does this course have a GitHub repository for ...   \n",
       "4     How can I structure my questions and answers f...   \n",
       "...                                                 ...   \n",
       "1825  What are some suggested titles for listing the...   \n",
       "1826  Should I list the Machine Learning Zoomcamp ex...   \n",
       "1827  In which LinkedIn sections can I incorporate m...   \n",
       "1828  Who gave advice on including a project link in...   \n",
       "1829  Who suggested showcasing progress through Link...   \n",
       "\n",
       "                         course  \n",
       "0     machine-learning-zoomcamp  \n",
       "1     machine-learning-zoomcamp  \n",
       "2     machine-learning-zoomcamp  \n",
       "3     machine-learning-zoomcamp  \n",
       "4     machine-learning-zoomcamp  \n",
       "...                         ...  \n",
       "1825  machine-learning-zoomcamp  \n",
       "1826  machine-learning-zoomcamp  \n",
       "1827  machine-learning-zoomcamp  \n",
       "1828  machine-learning-zoomcamp  \n",
       "1829  machine-learning-zoomcamp  \n",
       "\n",
       "[1830 rows x 5 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9bad8c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.3516946452113943)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score_vector = []\n",
    "for index, r in df_results.iterrows():\n",
    "    scores = rouge_scorer.get_scores(r.answer_llm, r.answer_orig)[0]\n",
    "    f1_score = scores['rouge-1']['f']\n",
    "    f1_score_vector.append(f1_score)\n",
    "np.mean(f1_score_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecfcbd0",
   "metadata": {},
   "source": [
    "## Q5 ANSWER\n",
    "c) 0.35"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c916c03",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
